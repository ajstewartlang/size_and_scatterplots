---
author_1: "Gabriel Strain"
author_2: "Andrew J. Stewart"
author_3: "Paul Warren"
author_4: "Caroline Jay"
author_1_email: "Gabriel.Strain@manchester.ac.uk"
author_2_email: "Andrew.J.Stewart@manchester.ac.uk"
author_3_email: "Paul.Warren@manchester.ac.uk"
author_4_email: "Caroline.Jay@manchester.ac.uk"
affiliation: "The University of Manchester"
acknowledgements: "lah di dah"
output:
  bookdown::pdf_book: # for automatic figure-numbering (https://bookdown.org/yihui/rmarkdown-cookbook/figure-number.html)
    keep_tex: yes
    template: template.tex
    citation_package: natbib
    fig_crop: no
title: "Point Size and Correlation Perception in Scatterplots"
editor_options: 
  markdown: 
    wrap: 72
bibliography: size_contrast_scatterplots.bib
abstract: |
  Place abstract here.
introduction: |
  Place intro here. Don't forget to put hypotheses
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::knit_hooks$set(crop = knitr::hook_pdfcrop)
# Knitting this document requires tinytex (install.packages("tinytex"))
# For formatting to be correct, additional tinytex packages are required
# Run tinytex:::install_yihui_pkgs() before knitting
```

```{r, include=FALSE}
set.seed(1234) # seed for all random number generation

# Loading packages
library(rticles)
library(tidyverse)
library(MASS)
library(emmeans)
library(scales)
library(buildmer)
library(lme4)
library(kableExtra)
library(afex)
library(papaja)
library(broom.mixed)
library(insight)
library(qwraps2)
library(lmerTest)
library(tinylabels)
library(ggdist)
library(ggpubr)
library(pwr)
library(geomtextpath)

# Comment out the following line if additional tinytex packages are already installed
#tinytex:::install_yihui_pkgs()
```

```{r eval-models, include=FALSE}
# in this script, models are cached. If eval_models <- FALSE, script will load
# cached models. Set eval_models <- TRUE to rebuild models from scratch
eval_models <- TRUE

if (eval_models == FALSE){
  lazyload_cache_dir('size_contrast_scatterplots/latex')
}
```

```{r load-data, include=FALSE}
# load in data files
size_anon <- read_csv("data/final_data.csv")
```

```{r wrangle, include = FALSE}
# function for wrangling data
wrangle <- function(anon_file) {
  
  literacy <- anon_file %>%
    filter(!is.na(q1_slider.response)) %>%
    rowwise() %>%
    mutate(literacy = sum(c(q1_slider.response, 
                            q2_slider.response, 
                            q3_slider.response, 
                            q4_slider.response, 
                            q5_slider.response))) %>%
    dplyr::select(participant,
           literacy)
  
# extract and process monitor and dot pitch information
# we assume standard 16:9 aspect ratio for monitors
  
  monitor_information <- anon_file %>%
    filter(!is.na(height)) %>%
    filter(!is.na(res_width)) %>%
    mutate(res_height = res_width*0.5625,
           width = height*0.5625,
           dot_pitch = ((sqrt(height^2 + width^2))/(sqrt(res_height^2 + res_width^2))) * 25.4) %>%
        dplyr::select(c("dot_pitch", "participant", "res_width"))
    
  
# extract demographic information
# link slider response numbers to gender categories
  
  demographics <- anon_file %>%
    filter(!is.na(gender_slider.response)) %>%
    mutate(gender_slider.response = recode(gender_slider.response,
                                         `1` = "F",
                                         `2` = "M",
                                         `3` = "NB")) %>%
  dplyr::select(matches(c("participant",
                          "age_textbox.text",
                          "gender_slider.response")))

# split plots_with_labels column into item and contrast condition columns 

anon_file <- anon_file %>%
  mutate(images = str_replace(images, pattern = "A", replacement = "-A")) %>%
  mutate(images = str_replace(images, pattern = "B", replacement = "-B")) %>%
  mutate(images = str_replace(images, pattern = "C", replacement = "-C")) %>%
  mutate(images = str_replace(images, pattern = "D", replacement = "-D")) %>%
  separate(images, c("item", "size"), sep = "-") %>%
  mutate(size = str_replace(size, pattern = ".png", replacement = "")) %>%
  mutate(item = str_replace(item, pattern = "all_plots/", replacement = ""))

# select relevant columns
# select only experimental items
# add literacy data
# change data types where appropriate
# output this file with suffix 'tidy'

anon_file %>%
  dplyr::select(c("participant",
                  "item",
                  "size",
                  "slider.response",
                  "my_rs",
                  "total_residuals",
                  "unique_item_no",
                  "session")) %>%
  filter(unique_item_no < 181) %>%
  inner_join(literacy, by = "participant") %>%
  inner_join(demographics, by = "participant") %>%
  inner_join(monitor_information, by = "participant") %>%
  mutate(across(matches(c("item", "size")), as_factor)) %>%
  dplyr::select(-c("__participant")) %>%
  mutate(difference = my_rs - slider.response) %>%
  assign(paste0(unique(anon_file$expName), "_tidy"),
           value = ., envir = .GlobalEnv)
}

# use wrangle function on anonmyised data files 

wrangle(size_anon)

# remove anon df from environment

rm(size_anon)

# check for missing age values

sum(is.na(exp_size_only_tidy$age_textbox.text))
```

```{r comparison-function, include=FALSE}
# this function takes a model and creates a nested model with the fixed effects 
# term removed for anova comparison
comparison <- function(model) {
  
  parens <- function(x) paste0("(",x,")")
  onlyBars <- function(form) reformulate(sapply(findbars(form),
                                              function(x)  parens(deparse(x))),
                                       response=".")
  onlyBars(formula(model))
  cmpr_model <- update(model,onlyBars(formula(model)))
  
  return(cmpr_model)
  
}
```

```{r anova-results-function, include=FALSE}
# this function takes two nested models, runs an anova, and the outputs the 
# Chi-square statistic, the degrees of freedom, and the p value to the global environment
anova_results <- function(model, cmpr_model) {
  
  model_name <- deparse(substitute(model))
  
  if (class(model) == "buildmer") model <- model@model
  if (class(cmpr_model) == "buildmer") cmpr_model <- cmpr_model@model
  
  anova_output <- anova(model, cmpr_model)
  
  assign(paste0(model_name, ".Chisq"),
         anova_output$Chisq[2],
         envir = .GlobalEnv)
  assign(paste0(model_name, ".df"),
         anova_output$Df[2],
         envir = .GlobalEnv)
  assign(paste0(model_name, ".p"),
         anova_output$`Pr(>Chisq)`[2],
         envir = .GlobalEnv)
  
}
```

```{r contrasts-extract, echo=FALSE}
# this function extracts test statistics and p values from model summaries
contrasts_extract <- function(model) {
  
  model_name <- deparse(substitute(model))
  
  if (class(model) == "buildmer") model <- model@model
  
  EMMs <- emmeans(model, pairwise ~ size)
  
  params <- as.data.frame(EMMs[2]) %>%
                            rename_with(str_replace,
                                        pattern = "contrasts.", replacement = "",
                                        matches("contrasts")) %>%
                            rename_with(str_to_title, !starts_with("p")) %>%
                            dplyr::select(c("Contrast", "Z.ratio", "p.value"))
  
  return(params)
  
}
```

```{r sum-stats-extract, echo = FALSE}
# generates summary statistics (mean and standard deviation)
sum_stats <- function(df) {
  
  stats <- df %>%
    filter(!is.na(difference)) %>%
    group_by(size) %>%
    summarise(mean = mean(difference),
              sd = sd(difference)) %>%
    rename_with(str_to_title) %>%
    rename_with(str_to_upper, starts_with("S"))
  
  return(stats)
  
}
```

```{r effect-size-function, include = FALSE}
get_effects_sizes <- function(model, d) {
  
  effect_sizes <- lme.dscore(model, data = d, type = "lme4")
  
  effects_df <- as.data.frame(effect_sizes[3])
  
  return(effects_df)
}
```

```{r dot-plot-function, include = FALSE}
dot_plot_function <- function(df) {

data <- df %>%
  group_by(size) %>%
  filter(!is.na(difference)) %>%
  filter(!is.na(size)) %>%
  summarise(
    mean = mean(difference),
    lci = t.test(difference, conf.level = 0.95)$conf.int[1],
    hci = t.test(difference, conf.level = 0.95)$conf.int[2],
  )

  data %>%
    mutate(size = fct_relevel(size, "A", "B", "C", "D")) %>%
    ggplot(aes(x = size, y = mean)) +
    geom_point() +
    #coord_cartesian(ylim = c(0, max_error))
    geom_errorbar(aes(ymin=lci, ymax=hci), colour="black", width=0.025, linewidth =1) +
    theme_ggdist() +
    labs(x = "Point Size Condition",
         y = "Mean Error") +
    theme(axis.text = element_text(size = 13),
          axis.title = element_text(size = 16))
}
```

```{r plot-sd-sd, include = FALSE}
plot_sd_sd_function <- function(df){
  df %>% 
  summarise(ppt_sd = sd(difference)) %>% 
  drop_na() %>% 
  group_by(size) %>% 
  summarise(mean_sd = mean(ppt_sd), sd_sd = sd(ppt_sd)) %>% 
  ggplot(aes(x = size, y = mean_sd)) +
  geom_point(size = 2) + 
  geom_errorbar(aes(ymin = mean_sd - sd_sd, ymax = mean_sd + sd_sd), width = 0.05, linewidth = 1) + 
  theme_ggdist() +
  ylim(0, .3) +
  labs(x = "Point Size Condition",
       y = "Mean Standard Deviation") +
        theme(axis.text = element_text(size = 13),
              axis.title = element_text(size = 16))
}
```

```{r error-bar-plot, include = FALSE}
plot_error_bars_function <- function(df, measure, l){
  df %>% 
  drop_na() %>% 
  group_by(size, my_rs) %>% 
  summarise(sd = sd(get(measure)), mean = mean(get(measure))) %>% 
  ggplot(aes(x = my_rs, y = mean)) +
  geom_point(size = 0.2) + 
  geom_errorbar(mapping = aes(ymin = mean + sd, ymax = mean - sd),width = 0.01, size = 0.3) +
  theme_ggdist() +
  scale_y_continuous(breaks = seq(0,1, 0.2)) +
  theme(strip.text = element_text(size = 6, margin = margin(1,0,1,0, "mm")), aspect.ratio = 1) +
  facet_wrap(size ~., ncol = 4, labeller = labeller(size = l)) +
    labs(x = "Objective r",
         y = "Mean r estimation") +
    xlim(0.2,1)
}

```

```{r labeller, include = FALSE}
labels_size <- c(A = "Non-Linear Decay", B = "Linear Decay", C = "Inverted Decay", D = "Standard Size")
```

```{r example-plots, include = FALSE}
example_plots <- function () {
  
  set.seed(1234)
  
  my_sample_size = 128
  
  my_desired_r = 0.6
  
  mean_variable_1 = 0
  sd_variable_1 = 1
  
  mean_variable_2 = 0
  sd_variable_2 = 1
  
  mu <- c(mean_variable_1, mean_variable_2) 
  
  myr <- my_desired_r * sqrt(sd_variable_1) * sqrt(sd_variable_2)
  
  mysigma <- matrix(c(sd_variable_1, myr, myr, sd_variable_2), 2, 2) 
  
  corr_data = as_tibble(mvrnorm(my_sample_size, mu, mysigma, empirical = TRUE))
  
  corr_model <- lm(V2 ~ V1, data = corr_data)
  
  my_residuals <- abs(residuals(corr_model))
  
  data_with_resid <- round(cbind(corr_data, my_residuals), 2)
  
slopes <- data_with_resid %>%
  mutate(slope_linear = my_residuals/3.2) %>%
  mutate(slope_0.25 = 1-(0.25)^my_residuals) %>%
  mutate(slope_inverted = (1 + (0.25)^ my_residuals)-1)
  
plot_example_function <- function (d, x, t) {
  
  set.seed(1234)
  
  ggplot(d, aes(x = V1, y = V2)) +
  scale_size_identity() +
  geom_point(aes(size = 4*(x + 0.2)), shape = 16)  +
  labs(x = "", y = "") +
  theme_classic() +
  theme(axis.text = element_blank(),
        plot.margin = unit(c(0,0,0,0), "cm"),
        legend.position = "none",
        plot.title = element_text(size = 15)) +
  labs(title = t)

}  

plots <- ggarrange(plot_example_function(slopes, (1-slopes$slope_0.25), "Non-linear Decay (b = 0.25)"),
                   plot_example_function(slopes, (1-slopes$slope_linear), "Linear Decay"),
                   plot_example_function(slopes, (1-slopes$slope_inverted), "Inverted Non-linear Decay"),
                   plot_example_function(slopes, 0.05, "Standard Size"))

return(plots)

}
```
# Related Work

## Correlation Perception

see Strain et al for a brief review of the history of correlation perception
testing with scatterplots

## Point Size

Hong et al paper will be useful here

## Dot Pitch and Crowdsourced Experiments

# Methodology

## Open Research Statement

The experiment was conducted according to the principles of open and reproducible research.
All data and analysis code are available at https://github.com/gjpstrain/size_contrast_and_scatterplots.
This repository contains instructions for building a docker image to fully 
reproduce the computational environment used, allowing for full replications
of stimulus generation, analyses, and the paper itself. The experiment was 
pre-registered with the OSF (https://osf.io/k4gd8).

## Participants

150 participants were recruited using the Prolific.co platform. Normal to
corrected-to-normal vision and English fluency were required for participation. As in
\cite{strain_2023}, and in accordance with previously published guidelines \cite{peer_2021},
participants were required to have completed at least 100 studies on Prolific, and were
required to have a Prolific score of at least 100, indicating acceptance on at least
100/101 previously completed studies. Participants who took part in any of our 
previous studies were prevented from participating.

## Stimuli

The data used to generated the scatterplots in the current study was identical to that
in \cite{strain_2023}. They were generated based on 45 uniformly distributed *r* values
between 0.2 and 0.99. Scatterplot points were generated based on bivariate normal 
distributions with standard deviations of 1 in each direction. Each scatterplot
had a 1:1 aspect ratio, was generated as a 1200 x 1200 pixel .png image, and was
scaled up or down according to the participant's monitor. See section \ref{dot-pitch-and-crowdsourced-experiments}
for a more detailed discussion of precise point sizes and dot pitch in crowd-sourced
experiments.

As in our previous study \cite{strain_2023}, we used equation 1 to map residuals 
to point sizes. We used a scaling factor of 4 and a constant of 0.2 to achieve a
minimum point size of 12/13 pixels, which is consistent with the point size on
a 1920 x 1080 monitor for both experiments in \cite{strain_2023}. Again, see section \ref{dot-pitch-and-crowdsourced-experiments}
for a discussion of dot pitch. Scripts detailing scatterplot and mask generation
can be found in the item preparation folder in the repository linked below.

\begin{equation}
  point-size = 1 - b^R
\end{equation}

## Dot Pitch and Crowdsourced Experiments

In our previous study \cite{strain_2023}, we had no way of obtaining dot pitch
or participant to monitor distance due to the online, crowdsourced nature of the 
experiments. Since then we have adopted a method for obtaining the height of a 
participant's monitor in inches \cite{screenscale}. Combining this with the
monitor resolution fetched from Psychopy and assuming a widescreen 16:9 aspect ratio
allows us to infer dot pitch and therefore the physical size of the points in our
experiment. Mean dot pitch was 

```{r}
mean(exp_size_only_tidy$dot_pitch)

sd(exp_size_only_tidy$dot_pitch)
```




## Design

The experiment used a fully repeated measures, within-participants design, with each
participant seeing and responding to each of the 180 scatterplots in a randomised order.
There were four scatterplots for each of the 45 *r* values corresponding to the
four levels of the size condition, examples of which can be see in figure \ref{plot-examples}.
Everything needed to run the experiment, including code, materials, instructions, and scripts, is
hosted at https://gitlab.pavlovia.org/Strain/exp_size_only.

```{r examples, warning=FALSE, echo=FALSE, message=FALSE, fig.asp=1, fig.show='hold', fig.cap="Four levels of the point size condition, demonstrated with an \\textit{r} value of 0.6"}
example_plots()
```


# Results

include short discussion of modelling paradigm and justification for it

# Discussion

```{r changes-with-r-size, warning=FALSE, echo=FALSE, message=FALSE, fig.align='left', fig.show='hold', fig.cap="hello", crop = TRUE, fig.env="figure*"}
plot_error_bars_function(exp_size_only_tidy, "difference", labels_size) +
    labs(y = "Mean r estimation error") +
    theme(title = element_text(size = 8)) +
    geom_hline(yintercept = 0, linetype = 2)
```

```{r dot-plot, warning=FALSE, echo=FALSE, message=FALSE, fig.align='center', fig.show='hold', fig.cap="hello", crop = TRUE, fig.env="figure*"}
dot_plot_function(exp_size_only_tidy) +
  scale_x_discrete(labels = c("Non-Linear\nSize Decay",
                              "Linear Size\nDecay",
                              "Inverted\nNon-Linear\nSize Decay",
                              "Standard Size")) +
  ylim(0,0.2)
```



























